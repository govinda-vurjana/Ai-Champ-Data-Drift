# Data Drift Detection RL Task - Comprehensive README

## üìã Table of Contents
1. [Problem Statement](#problem-statement)
2. [Objective](#objective)
3. [Background](#background)
4. [Architecture](#architecture)
5. [Model Information](#model-information)
6. [Test Suite Overview](#test-suite-overview)
7. [Test Cases Breakdown](#test-cases-breakdown)
8. [Why These Tests Matter](#why-these-tests-matter)
9. [Running the Evaluation](#running-the-evaluation)
10. [Understanding Results](#understanding-results)

---

## üéØ Problem Statement

### The Challenge
Models deployed to production naturally degrade as real-world data distributions change over time. This phenomenon is called **data drift**.

**The Problem:**
- ‚úó Models that performed well during development become outdated
- ‚úó User behaviors, market conditions, and data characteristics evolve
- ‚úó Performance metrics silently decrease without explicit monitoring
- ‚úó ML engineers face exhausting cycles of:
  - Model evaluation
  - Retraining
  - Redeployment
  - Monitoring
  - Repeat...

### Types of Data Drift

**1. Covariate Drift**
- Input distribution changes
- Model's output quality remains stable
- Example: User income distribution shifts, but model accuracy stays same
- Action: Usually needs retraining on new input distribution

**2. Concept Drift**
- Output quality degrades
- Input distribution remains stable
- Example: User preferences change, model accuracy drops
- Action: Requires model retraining with new logic

**3. Both Drifts**
- Both input AND output change
- Most dangerous scenario
- Action: Complete model review and retraining

---

## üéØ Objective

This evaluation tests whether an AI model (Claude) can implement **production-grade data drift detection and response functions**.

### Specific Goals

1. **Implement Drift Detection**
   - Accurately detect covariate drift (>20% input shift + stable quality)
   - Accurately detect concept drift (>10% quality drop + stable input)
   - Classify drift type correctly

2. **Calculate Business Impact**
   - Compute affected predictions
   - Calculate error counts
   - Estimate financial impact ($$$)
   - Handle edge cases (fractional days, extreme values)

3. **Recommend Actions**
   - Map drift severity to recommended action
   - Use thresholds: MONITOR ‚Üí INVESTIGATE ‚Üí RETRAIN ‚Üí ESCALATE
   - Handle unknown scenarios gracefully

4. **Achieve Target Accuracy**
   - Pass rate between 10-40%
   - Indicates model competency without over-fitting to test cases
   - Prevents gaming or memorization

---

<img width="1994" height="684" alt="image" src="https://github.com/user-attachments/assets/e6b8d97b-8c41-4dd5-ad3a-9ca60acdb81f" />




## üìö Background

### Why Data Drift Matters in Production

**Real-World Scenarios:**
- E-commerce: Product popularity shifts seasonally
- Finance: Market volatility changes transaction patterns
- Healthcare: Disease prevalence evolves
- Ad Tech: User interests shift over time

**Cost of Not Detecting Drift:**
```
Undetected Drift
    ‚Üì
Silently Declining Accuracy
    ‚Üì
Poor Predictions
    ‚Üì
Business Loss (customers, revenue, trust)
    ‚Üì
Crisis Mode Retraining
    ‚Üì
Expensive Recovery
```

### The Continuous Monitoring Loop

```
Deploy Model
    ‚Üì
Monitor for Drift
    ‚Üì
Drift Detected? 
    ‚îú‚îÄ YES ‚Üí Analyze Impact ‚Üí Retrain ‚Üí Redeploy ‚Üí Monitor
    ‚îî‚îÄ NO ‚Üí Continue Monitoring
```

---

## üèóÔ∏è Architecture

### System Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Data Drift Detection System                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  Production Model                                       ‚îÇ
‚îÇ  ‚îú‚îÄ Input Data (X)                                      ‚îÇ
‚îÇ  ‚îú‚îÄ Predictions (≈∑)                                    ‚îÇ
‚îÇ  ‚îî‚îÄ Quality Metrics (Accuracy, F1, AUC)                ‚îÇ
‚îÇ          ‚Üì                                              ‚îÇ
‚îÇ  Drift Detector                                         ‚îÇ
‚îÇ  ‚îú‚îÄ detect_covariate_drift()    [Input ‚Üí Stable]      ‚îÇ
‚îÇ  ‚îú‚îÄ detect_concept_drift()      [Quality ‚Üí Drop]      ‚îÇ
‚îÇ  ‚îî‚îÄ classify_drift()            [Type classification]  ‚îÇ
‚îÇ          ‚Üì                                              ‚îÇ
‚îÇ  Impact Calculator                                      ‚îÇ
‚îÇ  ‚îú‚îÄ calculate_drift_impact()    [$ impact]            ‚îÇ
‚îÇ  ‚îî‚îÄ determine_response_action() [Action mapping]      ‚îÇ
‚îÇ          ‚Üì                                              ‚îÇ
‚îÇ  Response                                               ‚îÇ
‚îÇ  ‚îú‚îÄ MONITOR: Continue watching                         ‚îÇ
‚îÇ  ‚îú‚îÄ INVESTIGATE: Review model & data                   ‚îÇ
‚îÇ  ‚îú‚îÄ RETRAIN: Update with new data                      ‚îÇ
‚îÇ  ‚îî‚îÄ ESCALATE: Critical - immediate action              ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ü§ñ Model Information

### Model Used: Claude Sonnet 4.5

**Deployment:** Google Vertex AI
```
API: Claude via Vertex AI
Region: Global
Project: august-beaker-470006-s8
Model: claude-sonnet-4-5
Max Tokens: 3,000
Temperature: Default (0.7)
```

### Why Claude Sonnet 4.5?
- Fast inference (suitable for repeated evaluations)
- Strong reasoning (can handle complex logic)
- Tool use capable (can test code with python_expression)
- Cost-effective for multiple runs (10 runs per evaluation)

### Evaluation Method

**Agent Loop:**
```
1. Claude reads task prompt
2. Claude writes Python functions
3. Claude tests with python_expression tool
4. Claude iterates until satisfied
5. Claude submits with submit_answer tool
6. System grades submitted code
7. Repeat 10 times (concurrent runs)
```

**Scoring: Binary (5-point scale)**
- 1 point per function if ALL its tests pass
- 0 points if ANY test fails
- Total: 0-5 points per run

---

## üìä Test Suite Overview

### Test Statistics

```
Total Functions:    5
Total Test Cases:   31
Easy Tests:         7
Medium Tests:      10
Hard Tests:         8
Extreme Tests:      6

Expected Pass Rate: 10-40%
Time per Run:       ~2-3 minutes
Total Time (10x):   ~20-30 minutes
```

### Test Distribution

| Function | Tests | Difficulty | Pass Requirement |
|----------|-------|-----------|------------------|
| detect_covariate_drift | 8 | Hard | ‚â•6/8 |
| detect_concept_drift | 5 | Hard | ‚â•2/5 |
| classify_drift | 6 | Easy | 6/6 (all) |
| calculate_drift_impact | 4 | Medium-Hard | ‚â•2/4 |
| determine_response_action | 8 | Medium | ‚â•5/8 |

---

## üß™ Test Cases Breakdown

### Function 1: detect_covariate_drift (8 tests)

**Rule:** Detect if `input_shift > 20% AND |quality_change| ‚â§ 5%`

| # | Shift | Quality | Expected | Type | Why Useful |
|---|-------|---------|----------|------|-----------|
| 1 | +40% | -1% | ‚úì DETECT | Sanity | Basic functionality |
| 2 | +15% | -6% | ‚úó NO | Trap | Quality drop veto |
| 3 | +19% | -2% | ‚úó NO | Boundary | Just below 20% threshold |
| 4 | +21% | +1% | ‚úì DETECT | Boundary | Just above 20% threshold |
| 5 | -25% | -1% | ‚úì DETECT | Negative | Magnitude matters |
| 6 | +20% | -7% | ‚úó NO | Veto | Quality drop always rejects |
| 7 | +5% | +1% | ‚úó NO | Easy | No drift |
| 8 | +30% | -4.5% | ‚úì DETECT | Extreme | Borderline tolerance |

**Key Insights:**
- ‚úì Tests exact 20% threshold (¬±1%)
- ‚úì Tests quality drop veto logic
- ‚úì Tests negative shifts (magnitude)
- ‚úì Tests floating-point precision

---

### Function 2: detect_concept_drift (5 tests)

**Rule:** Detect if `input_stable AND quality_drop > 10%`

| # | Quality | Input | Expected | Type | Why Useful |
|---|---------|-------|----------|------|-----------|
| 1 | -16% | Same | ‚úì DETECT | Sanity | Clear degradation |
| 2 | -9% | Same | ‚úó NO | Boundary | Below 10% threshold |
| 3 | -11% | +20% | ‚úó NO | Veto | Input changed = covariate |
| 4 | +2% | Same | ‚úó NO | Improve | No degradation |
| 5 | -11% | +5% | ‚úì DETECT | Edge | At input tolerance |

**Key Insights:**
- ‚úì Tests exact 10% quality threshold
- ‚úì Tests input stability requirement
- ‚úì Tests that improvement rejects detection
- ‚úì Tests tolerance boundaries

---

### Function 3: classify_drift (6 tests)

**Rule:** Simple if-logic mapping

| # | Input Shifted | Quality Dropped | Expected |
|---|---------------|-----------------|----------|
| 1 | True | False | 'covariate' |
| 2 | False | True | 'concept' |
| 3 | True | True | 'both' |
| 4 | False | False | 'none' |
| 5 | True | False | 'covariate' (repeat) |
| 6 | True | True | 'both' (repeat) |

**Key Insights:**
- ‚úì All tests should pass easily
- ‚úì Tests consistency (tests 5-6 repeat earlier)
- ‚úì Used as baseline to ensure basic competency

---

### Function 4: calculate_drift_impact (4 tests)

**Formula:**
```
predictions_affected = daily_predictions √ó days
errors = predictions_affected √ó error_rate
financial_impact = errors √ó cost
```

| # | Daily | Days | Rate | Cost | Expected Errors | Tolerance |
|---|-------|------|------|------|-----------------|-----------|
| 1 | 10k | 5 | 0.02 | $50 | 1,000 | ¬±1% |
| 2 | 10k | 7 | 0.0001 | $50 | 7 | ¬±5% |
| 3 | 10k | 2.5 | 0.01 | $100 | 250 | ¬±5% |
| 4 | 50k | 1 | 0.05 | $200 | 2,500 | ¬±2% |

**Key Insights:**
- ‚úì Test 1: Standard case with tight tolerance
- ‚úì Test 2: Extreme precision (error rate 0.0001)
- ‚úì Test 3: Fractional days (floating-point)
- ‚úì Test 4: Large scale ($500k+ impact)

---

### Function 5: determine_response_action (8 tests)

**Thresholds:**
```
0.0 - 0.3  ‚Üí MONITOR
0.3 - 0.5  ‚Üí INVESTIGATE
0.5 - 0.9  ‚Üí RETRAIN
> 0.9      ‚Üí ESCALATE
```

| # | Drift Type | Severity | Expected | Why |
|---|-----------|----------|----------|-----|
| 1 | covariate | 0.29 | MONITOR | Low severity |
| 2 | concept | 0.35 | INVESTIGATE | Mid-range |
| 3 | both | 0.51 | RETRAIN | High severity |
| 4 | concept | 0.91 | ESCALATE | Critical |
| 5 | covariate | 0.5 | INVESTIGATE | Exact boundary |
| 6 | both | 0.75 | RETRAIN | Normal high |
| 7 | both | 0.95 | ESCALATE | Very critical |
| 8 | unknown | 0.45 | INVESTIGATE | Unknown type |

**Key Insights:**
- ‚úì Tests exact threshold boundaries (0.3, 0.5, 0.9)
- ‚úì Tests unknown drift type handling
- ‚úì Tests severity mapping accuracy

---

## üí° Why These Tests Matter

### 1. Boundary Testing (Most Important)

**Why Critical:** Off-by-one errors are common
```python
# Wrong: if shift >= 0.20
# Right: if shift > 0.20

# 20% exactly:
# Wrong approach: DETECT ‚úó
# Right approach: NO (at boundary) ‚úì
```

**Test Examples:**
- Covariate: 19% vs 20% vs 21% shifts
- Concept: 9% vs 10% vs 11% quality drops
- Action: Severity 0.29 vs 0.30 vs 0.31

### 2. Veto Logic (Real-World Requirement)

**Why Matters:** Real systems have rejections
```
Covariate Detection:
- Quality drop > 5% ‚Üí ALWAYS reject (it's concept drift, not covariate)

Concept Detection:
- Input changed > 5% ‚Üí ALWAYS reject (it's covariate, not concept)
- Quality improved ‚Üí ALWAYS reject (degradation requirement)
```

### 3. Precision Testing (Edge Cases)

**Why Matters:** Financial impact calculations need accuracy
```
Error rate 0.0001 √ó 70,000 predictions = 7 errors EXACTLY
Not 6.9 or 7.1 - EXACTLY 7
```

### 4. Scale Variation (Production Readiness)

**Why Matters:** Models must work at all scales
```
From: 1 prediction, $1 cost
To: 50,000 predictions/day, $500,000 impact
```

### 5. Consistency (Reliability)

**Why Matters:** Production systems must be deterministic
```
classify_drift(True, False) ‚Üí ALWAYS returns 'covariate'
Never random, never depends on call order
```

---

## üöÄ Running the Evaluation

### Quick Start

```bash
# Run with progress tracking (concurrent)
python main_WITH_PROGRESS.py

# Expected output:
# [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 8/10
# Score: 4/5 | Avg: 3.2 | Max: 5/5 | ETA: 120s
```

### Understanding Progress

```
Progress Bar:   [‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] Shows overall completion
Current Score:  5/5 (Run N passed all 5 functions)
Average Score:  3.5 (Average across all runs so far)
Max Score:      5/5 (Best score achieved)
ETA:            120s (Estimated time remaining)
```

### Configuration Options

```python
# main_WITH_PROGRESS.py
asyncio.run(main(
    num_runs=10,      # Number of runs (default: 10)
    concurrent=True   # Parallel execution (default: True)
))
```

---

## üìà Understanding Results

### Final Report Example

```
FINAL REPORT
======================================================================
API Mode: Vertex AI
Model: Claude Sonnet 4.5 (Vertex AI)
Total Runs: 10
Fully Passed Runs (5/5): 2/10
Pass Rate: 20.0%
Target Range (10-40%): ‚úì YES
Score Distribution: [5, 4, 4, 3, 3, 2, 2, 1, 1, 0]
======================================================================
```

### Interpretation

| Pass Rate | Status | Meaning |
|-----------|--------|---------|
| 0-10% | Below Target | Tests too hard; adjust tolerances |
| 10-40% | ‚úì Optimal | Model has good understanding |
| 40-70% | Above Target | Tests too easy; add complexity |
| 70%+ | Way Too Easy | Tests insufficient |

### Score Distribution Analysis

```
Score: [5, 4, 4, 3, 3, 2, 2, 1, 1, 0]
        ‚Üì
Strong passes (5/5):    2 runs   - 20% perfect
Good passes (3-4/5):    4 runs   - 40% mostly correct
Weak passes (1-2/5):    3 runs   - 30% partial success
Failures (0/5):         1 run    - 10% complete failure

Average: 2.5/5 = 50% of test suite passing
Interpretation: Model understands core concepts but struggles
               with boundaries and edge cases
```

---

## üìã File Reference

### main_WITH_PROGRESS.py
Updated main file with real-time progress tracking
- ‚úÖ Progress bar during concurrent runs
- ‚úÖ Real-time statistics (avg, max score)
- ‚úÖ ETA countdown
- ‚úÖ Final summary statistics

### Key Changes from Original
```python
# NEW: ProgressTracker class
progress = ProgressTracker(num_runs)
progress.update(run_id, score)  # Called per run
progress.final_stats()          # Called at end

# Shows:
# ‚úì Real-time progress bar
# ‚úì Current/average/max scores
# ‚úì Time elapsed and ETA
```

---

## üîç Troubleshooting

### Issue: Tests Taking Too Long
```
Solution: Reduce num_runs or set concurrent=False for debugging
python -c "asyncio.run(main(num_runs=3, concurrent=True))"
```

### Issue: All Runs Failing (0% Pass Rate)
```
Likely Cause: Claude returning wrong data types
Check: Are functions returning dicts with correct keys?
       detect_covariate_drift() ‚Üí {'detected': bool}
       classify_drift() ‚Üí {'type': str}
       calculate_drift_impact() ‚Üí {'predictions_affected': int, 'errors': int, 'financial_impact': float}
```

### Issue: Some Functions Always Pass, Others Always Fail
```
Example: classify_drift always passes, covariate always fails
Likely Cause: Easy vs hard difficulty difference
Solution: Adjust thresholds in grader for specific function
```

---

## üìä Expected Performance

### Baseline (Generic Implementation)
- Pass Rate: ~30% (3/5 functions)
- Strong: classify_drift (easy logic)
- Weak: covariate/concept drift (boundary logic)

### Strong Implementation
- Pass Rate: ~50% (2-3 functions per run)
- All functions partially working
- Struggles with boundary precision

### Expert Implementation
- Pass Rate: ~70%+ (4-5 functions per run)
- All boundaries correct
- Handles all edge cases
- Consistent performance

---

## üéì Learning Outcomes

After this evaluation, you should understand:

1. ‚úÖ **Data Drift Types**
   - Covariate drift (input change)
   - Concept drift (quality change)
   - Combined drift

2. ‚úÖ **Threshold Precision**
   - Why exact boundaries matter
   - Impact of off-by-one errors
   - Tolerance handling

3. ‚úÖ **Business Impact Calculation**
   - Financial impact metrics
   - Scale considerations
   - Precision requirements

4. ‚úÖ **Production ML**
   - Continuous monitoring needs
   - Automated retraining triggers
   - Alert escalation strategies

---

**Last Updated:** November 6, 2025
**Task:** Data Drift Detection RL Evaluation
**Status:** Production Ready ‚úÖ
